use std.arena
use std.array
use src.lexer

alias Node_Index int

alias Node_Kind int
const (
   NODE_ATOM
   NODE_LIST
   NODE_EVAL

   NODE_TYPE
   NODE_BLOCK
   NODE_VAR
   NODE_RULE
   NODE_RUN
   COUNT_NODES
)

const NODE_LIST_ELEMENTS = 0

const NODE_EVAL_LHS = 0
const NODE_EVAL_OP = 1
const NODE_EVAL_RHS = 2

const NODE_TYPE_EXPRS = 0

const NODE_BLOCK_STMTS = 0

const NODE_VAR_NAME = 0
const NODE_VAR_TYPE = 1
const NODE_VAR_BODY = 2

const NODE_RULE_STATE = 0
const NODE_RULE_READ = 1
const NODE_RULE_WRITE = 2
const NODE_RULE_ACTION = 3
const NODE_RULE_NEXT = 4

const NODE_RUN_STATE = 0
const NODE_RUN_TAPE = 1

struct Node {
   kind Node_Kind
   token Token

   nodes [5]Node_Index
   next Node_Index
}

const NODES_CAP = 1024*1024
let nodes [NODES_CAP]Node
let nodes_count int

fn node_new(kind Node_Kind, token Token) Node_Index {
   assert nodes_count < NODES_CAP
   nodes[nodes_count].kind = kind
   nodes[nodes_count].token = token
   nodes_count += 1
   return nodes_count - 1
}

fn node_list_push(list *Node_Index, node Node_Index) *Node_Index {
   if *list != 0 {
      list = &nodes[*list].next
   }

   *list = node
   return list
}

fn node_list_find(list Node_Index, node Node_Index) bool {
   for list != 0 {
      if nodes[list].token.str == nodes[node].token.str {
         nodes[node].token.data = list
         return true
      }
      list = nodes[list].next
   }
   return false
}

const TYPES_CAP = 1024
let types [TYPES_CAP]Node_Index
let types_count int

fn types_push(node Node_Index) {
   assert types_count < TYPES_CAP
   types[types_count] = node
   types_count += 1
}

fn types_find(name Str, index *int) bool {
   for let i = 0, i < types_count, i += 1 {
      if nodes[types[i]].token.str == name {
         *index = i
         return true
      }
   }
   return false
}

const STMTS_CAP = 1024
let stmts [STMTS_CAP]Node_Index
let stmts_count int

fn stmts_push(node Node_Index) {
   assert stmts_count < STMTS_CAP
   stmts[stmts_count] = node
   stmts_count += 1
}

let var_names [1024]Node_Index
let var_names_count int

fn error_unexpected(token Token) {
   &stderr << token.pos << "error: unexpected " << str_from_token_kind(token.kind) << "\n"
   exit(1)
}

assert COUNT_TOKENS == 15
fn parse_atom() Node_Index {
   let node Node_Index
   let token = lexer_next()

   match token.kind {
      TOKEN_INTEGER, TOKEN_SYMBOL => node = node_new(NODE_ATOM, token)
      else => error_unexpected(token)
   }

   return node
}

assert COUNT_TOKENS == 15
fn parse_expr() Node_Index {
   let node Node_Index
   let token = lexer_next()

   match token.kind {
      TOKEN_LPAREN => {
         node = node_new(NODE_LIST, token)

         if lexer_read(TOKEN_RPAREN) {
            &stderr << token.pos << "error: lists can't be empty\n"
            exit(1)
         }

         let elements = &nodes[node].nodes[NODE_LIST_ELEMENTS]
         for true {
            elements = node_list_push(elements, parse_expr())
            if lexer_read(TOKEN_RPAREN) {
               break
            }
         }
      }
      TOKEN_LBRACKET => {
         node = node_new(NODE_EVAL, token)
         nodes[node].nodes[NODE_EVAL_LHS] = parse_expr()
         nodes[node].nodes[NODE_EVAL_OP] = parse_atom()
         nodes[node].nodes[NODE_EVAL_RHS] = parse_expr()
         lexer_expect(TOKEN_RBRACKET)
      }
      else => {
         lexer_buffer(token)
         node = parse_atom()
      }
   }

   return node
}

assert COUNT_TOKENS == 15
fn parse_stmt() Node_Index {
   let node Node_Index
   let token = lexer_next()

   match token.kind {
      TOKEN_TYPE => {
         let name = lexer_expect(TOKEN_SYMBOL)
         node = node_new(NODE_TYPE, name)

         let index int
         if types_find(name.str, &index) {
            &stderr << name.pos << "error: redefinition of type '" << name.str << "'\n"
            exit(1)
         }

         lexer_expect(TOKEN_LBRACE)
         if lexer_read(TOKEN_RBRACE) {
            &stderr << token.pos << "error: types can't be empty\n"
            exit(1)
         }

         let exprs = &nodes[node].nodes[NODE_TYPE_EXPRS]
         for true {
            let expr = parse_expr()
            if node_list_find(*exprs, expr) {
               &stderr << nodes[expr].token.pos << "error: types must contain only unique values\n"
               exit(1)
            }
            exprs = node_list_push(exprs, expr)
            if lexer_read(TOKEN_RBRACE) {
               break
            }
         }

         types_push(node)
      }
      TOKEN_LBRACE => {
         if lexer_read(TOKEN_RBRACE) {
            &stderr << token.pos << "error: blocks can't be empty\n"
            exit(1)
         }

         node = node_new(NODE_BLOCK, token)
         let stmts = &nodes[node].nodes[NODE_BLOCK_STMTS]
         for true {
            stmts = node_list_push(stmts, parse_stmt())
            if lexer_read(TOKEN_RBRACE) {
               break
            }
         }

         stmts_push(node)
      }
      TOKEN_VAR => {
         node = node_new(NODE_VAR, token)

         var_names_count = 0
         for true {
            var_names[var_names_count] = parse_atom()
            var_names_count += 1
            if lexer_read(TOKEN_COLON) {
               break
            }
         }

         let type Node_Index
         let type_token = lexer_expect(TOKEN_SYMBOL)
         let index int
         if type_token.str == "Integer" {
            type = node_new(NODE_TYPE, type_token)
         } else if types_find(type_token.str, &index) {
            type = types[index]
         } else {
            &stdout << type_token.pos << "error: unknown type '" << type_token.str << "'\n"
            exit(1)
         }

         nodes[node].nodes[NODE_VAR_TYPE] = type
         
         node = parse_stmt()
         for let i = var_names_count - 1, i >= 0, i -= 1 {
            let new_var = node_new(NODE_VAR, token)
            nodes[new_var].nodes[NODE_VAR_NAME] = var_names[i]
            nodes[new_var].nodes[NODE_VAR_TYPE] = type
            nodes[new_var].nodes[NODE_VAR_BODY] = node
            node = new_var
         }
         
         stmts_push(node)
      }
      TOKEN_RULE => {
         node = node_new(NODE_RULE, token)
         nodes[node].nodes[NODE_RULE_STATE] = parse_expr()
         nodes[node].nodes[NODE_RULE_READ] = parse_expr()
         nodes[node].nodes[NODE_RULE_WRITE] = parse_expr()
         nodes[node].nodes[NODE_RULE_ACTION] = parse_atom()
         nodes[node].nodes[NODE_RULE_NEXT] = parse_expr()
         stmts_push(node)
      }
      TOKEN_RUN, TOKEN_TRACE => {
         node = node_new(NODE_RUN, token)
         nodes[node].token.data = (token.kind == TOKEN_TRACE) as int
         nodes[node].nodes[NODE_RUN_STATE] = parse_expr()

         lexer_expect(TOKEN_LBRACE)
         if lexer_read(TOKEN_RBRACE) {
            &stderr << token.pos << "error: tapes can't be empty\n"
            exit(1)
         }

         let tape = &nodes[node].nodes[NODE_RUN_TAPE]
         for true {
            tape = node_list_push(tape, parse_expr())
            if lexer_read(TOKEN_RBRACE) {
               break
            }
         }
      }
      else => error_unexpected(token)
   }

   return node
}
